// Copyright 2020 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto2";

package learning.adanets.phoenix.meta.proto.distillation_spec;



message AdaptivelyBalancingLossesSpec {
  // Number of trials to hit maximum_lambda.
  // See: https://goto.google.com/churn-onepager
  optional int32 num_ramp_trials = 1;
  // The minimum and maximum lambda allowed to balance the label loss and the
  // distillation loss.
  optional float minimum_lambda = 2 [default = 1.0];
  optional float maximum_lambda = 3 [default = 1.0];
}

// Next id: 6
message DistillationSpec {
  enum DistillationType {
    UNKNOWN_DISTILLATION_TYPE = 0;
    // Mean square error between the teacher logits and the student logits.
    // Labels are not used in this distillation mode.
    MSE_LOGITS = 1;
    // Mean square error between the teacher predictions (softmax over its
    // logits) and the student logits. (Don't use with regression).
    // Labels are not used in this distillation mode.
    MSE_SOFTMAX = 2;
    // Cross entropy loss between teacher predictions (softmax over its
    // logits) and the student logits. (Don't use with regression).
    // Labels are not used in this distillation mode.
    CROSS_ENTROPY = 3;
    // Incrementally rely on cross entropy loss from distilling the teacher.
    // For more info, please see:
    // https://goto.google.com/churn-onepager
    ADAPTIVELY_BALANCE_LOSSES = 5;
  }

  optional DistillationType distillation_type = 1;

  // Used when distillation_loss_type is ADAPTIVELY_BALANCE_LOSSES
  optional AdaptivelyBalancingLossesSpec balance_losses_spec = 5;

  // Start distilling starting trial id `minimal_pool_size`.
  // If distillation and intermixed ensemble search are specified at the same
  // time, this field is ignored, and distillation happens immediately after
  // an ensemble search trial.
  // If distillation and nonadaptive or adaptive or residual ensemble search are
  // specified for the same run, the minimal_pool_size for each should be
  // different. Otherwise, distillation will be ignored.
  optional int32 minimal_pool_size = 2 [default = 100];

  // The temperature of the softmax, when SOFTMAX is the DistillationType.
  // output = softmax(logits / temperature)
  optional float temperature = 3 [default = 1.0];
}
